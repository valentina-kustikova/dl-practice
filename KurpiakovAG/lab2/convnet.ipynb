{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxtTeUCOcF46",
        "outputId": "bc44d824-3db2-406d-e24d-4266ca81b1a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Training WideNetwork ===\n",
            "Epoch 01/20 | loss=1.5787 | train_acc=0.4178\n",
            "Epoch 02/20 | loss=1.2034 | train_acc=0.5684\n",
            "Epoch 03/20 | loss=1.0269 | train_acc=0.6372\n",
            "Epoch 04/20 | loss=0.9231 | train_acc=0.6755\n",
            "Epoch 05/20 | loss=0.8458 | train_acc=0.7018\n",
            "Epoch 06/20 | loss=0.7736 | train_acc=0.7304\n",
            "Epoch 07/20 | loss=0.7159 | train_acc=0.7497\n",
            "Epoch 08/20 | loss=0.6609 | train_acc=0.7695\n",
            "Epoch 09/20 | loss=0.6134 | train_acc=0.7860\n",
            "Epoch 10/20 | loss=0.5672 | train_acc=0.8029\n",
            "Epoch 11/20 | loss=0.5301 | train_acc=0.8156\n",
            "Epoch 12/20 | loss=0.4864 | train_acc=0.8297\n",
            "Epoch 13/20 | loss=0.4499 | train_acc=0.8430\n",
            "Epoch 14/20 | loss=0.4135 | train_acc=0.8566\n",
            "Epoch 15/20 | loss=0.3851 | train_acc=0.8661\n",
            "Epoch 16/20 | loss=0.3504 | train_acc=0.8785\n",
            "Epoch 17/20 | loss=0.3210 | train_acc=0.8888\n",
            "Epoch 18/20 | loss=0.2902 | train_acc=0.9005\n",
            "Epoch 19/20 | loss=0.2662 | train_acc=0.9083\n",
            "Epoch 20/20 | loss=0.2395 | train_acc=0.9172\n",
            "Final Results for WideNetwork:\n",
            "Test Loss: 0.8059, Test Accuracy: 76.57%\n",
            "Training Time: 283.74 seconds\n",
            "\n",
            "\n",
            "=== Training SmallNetwork ===\n",
            "Epoch 01/20 | loss=1.5969 | train_acc=0.4098\n",
            "Epoch 02/20 | loss=1.2449 | train_acc=0.5550\n",
            "Epoch 03/20 | loss=1.0731 | train_acc=0.6203\n",
            "Epoch 04/20 | loss=0.9636 | train_acc=0.6600\n",
            "Epoch 05/20 | loss=0.8780 | train_acc=0.6915\n",
            "Epoch 06/20 | loss=0.8089 | train_acc=0.7169\n",
            "Epoch 07/20 | loss=0.7501 | train_acc=0.7367\n",
            "Epoch 08/20 | loss=0.6960 | train_acc=0.7574\n",
            "Epoch 09/20 | loss=0.6375 | train_acc=0.7776\n",
            "Epoch 10/20 | loss=0.5987 | train_acc=0.7926\n",
            "Epoch 11/20 | loss=0.5522 | train_acc=0.8078\n",
            "Epoch 12/20 | loss=0.5121 | train_acc=0.8239\n",
            "Epoch 13/20 | loss=0.4690 | train_acc=0.8370\n",
            "Epoch 14/20 | loss=0.4365 | train_acc=0.8476\n",
            "Epoch 15/20 | loss=0.4022 | train_acc=0.8605\n",
            "Epoch 16/20 | loss=0.3696 | train_acc=0.8716\n",
            "Epoch 17/20 | loss=0.3371 | train_acc=0.8827\n",
            "Epoch 18/20 | loss=0.3068 | train_acc=0.8949\n",
            "Epoch 19/20 | loss=0.2789 | train_acc=0.9033\n",
            "Epoch 20/20 | loss=0.2550 | train_acc=0.9130\n",
            "Final Results for SmallNetwork:\n",
            "Test Loss: 0.8504, Test Accuracy: 75.87%\n",
            "Training Time: 267.72 seconds\n",
            "\n",
            "\n",
            "=== Training Network ===\n",
            "Epoch 01/20 | loss=1.1586 | train_acc=0.5792\n",
            "Epoch 02/20 | loss=0.6908 | train_acc=0.7586\n",
            "Epoch 03/20 | loss=0.5211 | train_acc=0.8207\n",
            "Epoch 04/20 | loss=0.4111 | train_acc=0.8583\n",
            "Epoch 05/20 | loss=0.3284 | train_acc=0.8866\n",
            "Epoch 06/20 | loss=0.2558 | train_acc=0.9105\n",
            "Epoch 07/20 | loss=0.1936 | train_acc=0.9314\n",
            "Epoch 08/20 | loss=0.1402 | train_acc=0.9501\n",
            "Epoch 09/20 | loss=0.1082 | train_acc=0.9624\n",
            "Epoch 10/20 | loss=0.0851 | train_acc=0.9700\n",
            "Epoch 11/20 | loss=0.0701 | train_acc=0.9753\n",
            "Epoch 12/20 | loss=0.0610 | train_acc=0.9792\n",
            "Epoch 13/20 | loss=0.0560 | train_acc=0.9805\n",
            "Epoch 14/20 | loss=0.0433 | train_acc=0.9848\n",
            "Epoch 15/20 | loss=0.0429 | train_acc=0.9848\n",
            "Epoch 16/20 | loss=0.0455 | train_acc=0.9838\n",
            "Epoch 17/20 | loss=0.0309 | train_acc=0.9897\n",
            "Epoch 18/20 | loss=0.0380 | train_acc=0.9871\n",
            "Epoch 19/20 | loss=0.0349 | train_acc=0.9883\n",
            "Epoch 20/20 | loss=0.0301 | train_acc=0.9899\n",
            "Final Results for Network:\n",
            "Test Loss: 0.7944, Test Accuracy: 85.16%\n",
            "Training Time: 487.31 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, pin_memory=True, num_workers=2, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, pin_memory=True, num_workers=2, shuffle=False)\n",
        "\n",
        "def conv_blk(inputChannels, outputChannels, pooling):\n",
        "    layers = [nn.Conv2d(inputChannels, outputChannels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(outputChannels),\n",
        "              nn.ReLU()]\n",
        "\n",
        "    if pooling:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, inputChannels, outputChannels):\n",
        "        super(Network, self).__init__()\n",
        "        self._block = nn.Sequential(\n",
        "            conv_blk(inputChannels, 64, False),\n",
        "            conv_blk(64, 64, False),\n",
        "            conv_blk(64, 128, True),\n",
        "            conv_blk(128, 128, False),\n",
        "            conv_blk(128, 256, True),\n",
        "            conv_blk(256, 256, False),\n",
        "            conv_blk(256, 512, True),\n",
        "            conv_blk(512, 512, False)\n",
        "        )\n",
        "\n",
        "        self._adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self._res = nn.Linear(512, outputChannels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self._block(X)\n",
        "        out = self._adaptive_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self._res(out)\n",
        "        return out\n",
        "\n",
        "class WideNetwork(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels):\n",
        "        super().__init__()\n",
        "        self._block = nn.Sequential(\n",
        "            nn.Conv2d(inChannels, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self._adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self._res = nn.Linear(256, outChannels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self._block(X)\n",
        "        out = self._adaptive_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self._res(out)\n",
        "        return out\n",
        "\n",
        "class SmallNetwork(nn.Module):\n",
        "    def __init__(self, inChannels, outChannels):\n",
        "        super().__init__()\n",
        "        self._block = nn.Sequential(\n",
        "            nn.Conv2d(inChannels, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self._adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self._res = nn.Linear(256, outChannels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self._block(X)\n",
        "        out = self._adaptive_pool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self._res(out)\n",
        "        return out\n",
        "\n",
        "def train_once(model, train_loader, criterion, optimizer, device):\n",
        "    avg_accuracy = []\n",
        "    avg_loss = []\n",
        "\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        image = data[0].to(device)\n",
        "        label = data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(image)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        avg_loss.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.argmax(dim=1)\n",
        "        accuracy = (pred == label).float().mean()\n",
        "        avg_accuracy.append(accuracy.item())\n",
        "\n",
        "    return np.mean(avg_loss), np.mean(avg_accuracy)\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    models = [\n",
        "        WideNetwork(3, 10).to(device),\n",
        "        SmallNetwork(3, 10).to(device),\n",
        "        Network(3, 10).to(device)\n",
        "    ]\n",
        "\n",
        "    model_names = [\"WideNetwork\", \"SmallNetwork\", \"Network\"]\n",
        "\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        print(f\"\\n=== Training {model_names[i]} ===\")\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss().to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        loss_list = []\n",
        "        acc_list = []\n",
        "\n",
        "        epochs = 20\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            epoch_loss, train_acc = train_once(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "            print(f\"Epoch {epoch:02d}/{epochs} | loss={epoch_loss:.4f} | train_acc={train_acc:.4f}\")\n",
        "\n",
        "            loss_list.append(epoch_loss)\n",
        "            acc_list.append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images = data[0].to(device)\n",
        "                labels = data[1].to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        avg_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Final Results for {model_names[i]}:\")\n",
        "        print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "        print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
